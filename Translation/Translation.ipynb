{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f8d8429-fa27-4cca-9500-5da6329a1b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from huggingface_hub import notebook_login\n",
    "import evaluate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d6bab49-ba41-4cc2-a403-fddc659869a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\prafu\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\kde4\\243129fb2398d5b0b4f7f6831ab27ad84774b7ce374cf10f60f6e1ff331648ac (last modified on Tue Jul 15 15:13:50 2025) since it couldn't be found locally at kde4, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'translation'],\n",
       "        num_rows: 97227\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"kde4\", lang1=\"en\", lang2=\"hi\", trust_remote_code=True)\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "540d6331-3fb4-41fd-a69e-fc1ed5f809e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'translation'],\n",
       "        num_rows: 87504\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'translation'],\n",
       "        num_rows: 9723\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_datasets = raw_datasets[\"train\"].train_test_split(train_size=0.9, seed=20)\n",
    "split_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b03cb11-2e57-40d6-8924-393fe3f6d075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '14666',\n",
       " 'translation': {'en': 'This button saves all your changes and exits the program.',\n",
       "  'hi': 'यह बटन आपके सभी परिवर्तनों को सहेजता है तथा प्रोग्राम को बाहर कर देता है.'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2401a1-7f06-4db0-b116-13a7895cc8ef",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b96c89f-998f-4399-8c90-97762daef560",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"Helsinki-NLP/opus-mt-en-hi\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2764ee74-7fcc-447a-b008-6228416c2b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [239, 2612, 16779, 98, 85, 1386, 10, 6759, 16, 4, 1720, 3, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [60, 2101, 522, 289, 1382, 86, 18, 27712, 5, 1231, 1546, 18, 587, 57, 355, 5, 3, 0]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_en_sentence = split_datasets[\"train\"][0][\"translation\"][\"en\"]\n",
    "sample_hin_sentence = split_datasets[\"train\"][0][\"translation\"][\"hi\"]\n",
    "\n",
    "# Here we need to provide text target, labels will contains ids in target language, and input_ids will contains ids in input language\n",
    "sample_input = tokenizer(sample_en_sentence, text_target=sample_hin_sentence)\n",
    "sample_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66d3d256-f987-418a-b4dd-e429a60dd144",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 128\n",
    "def process_text(examples):\n",
    "    input_sentences = [ex[\"en\"] for ex in examples[\"translation\"]]\n",
    "    target_sentences = [ex[\"hi\"] for ex in examples[\"translation\"]]\n",
    "\n",
    "    model_inputs = tokenizer(input_sentences, text_target=target_sentences, max_length=max_length, truncation=True)\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34122620-aabc-485c-af30-98de3fa0b98b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 87504\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 9723\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = split_datasets.map(\n",
    "    process_text,\n",
    "    batched=True,\n",
    "    remove_columns=split_datasets[\"train\"].column_names\n",
    ")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bf0f74-3d1d-4ea3-9696-046fa972fc22",
   "metadata": {},
   "source": [
    "### FineTuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2b126bb-ec6b-4c92-b1a8-beb47ba0e4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "974cf4e4-bae8-4357-a82e-81c674af1055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  239,  2612, 16779,    98,    85,  1386,    10,  6759,    16,     4,\n",
       "          1720,     3,     0],\n",
       "        [ 2866, 16910,     0, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
       "         61949, 61949, 61949]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'labels': tensor([[   60,  2101,   522,   289,  1382,    86,    18, 27712,     5,  1231,\n",
       "          1546,    18,   587,    57,   355,     5,     3,     0],\n",
       "        [ 8161, 10238,     0,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100]]), 'decoder_input_ids': tensor([[61949,    60,  2101,   522,   289,  1382,    86,    18, 27712,     5,\n",
       "          1231,  1546,    18,   587,    57,   355,     5,     3],\n",
       "        [61949,  8161, 10238,     0, 61949, 61949, 61949, 61949, 61949, 61949,\n",
       "         61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949]])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_batch = [tokenized_datasets[\"train\"][i] for i in range(2)]\n",
    "\n",
    "batch = data_collator(sample_batch)\n",
    "# Here we can see that labels are padded with -100 and decoder_input_ids are shifted version of labels\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7a02b9-bf06-4ae5-9c8b-29170642b7e7",
   "metadata": {},
   "source": [
    "The score ranges from 0 to 100. The higher the better\n",
    "\n",
    "param score: The BLEU score.\n",
    "\n",
    "param counts: List of counts of correct ngrams, 1 <= n <= max_ngram_order\n",
    "\n",
    "param totals: List of counts of total ngrams, 1 <= n <= max_ngram_order\n",
    "\n",
    "param precisions: List of precisions, 1 <= n <= max_ngram_order\n",
    "\n",
    "param bp: The brevity penalty.\n",
    "\n",
    "param sys_len: The cumulative system length.\n",
    "\n",
    "param ref_len: The cumulative reference length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b8d3e63-4643-42ca-a898-645e6eb0c83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\prafu\\.cache\\huggingface\\modules\\evaluate_modules\\metrics\\evaluate-metric--sacrebleu\\28676bf65b4f88b276df566e48e603732d0b4afd237603ebdf92acaacf5be99b (last modified on Tue Jul 15 15:53:27 2025) since it couldn't be found locally at evaluate-metric--sacrebleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 46.750469682990165,\n",
       " 'counts': [11, 6, 4, 3],\n",
       " 'totals': [12, 11, 10, 9],\n",
       " 'precisions': [91.66666666666667,\n",
       "  54.54545454545455,\n",
       "  40.0,\n",
       "  33.333333333333336],\n",
       " 'bp': 0.9200444146293233,\n",
       " 'sys_len': 12,\n",
       " 'ref_len': 13}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = evaluate.load(\"sacrebleu\")\n",
    "\n",
    "# Prediction will be a list of string, but references will be a list of list of strings as there are multiple acceptable translation of \n",
    "# a the same sentence\n",
    "predictions = [\n",
    "    \"This plugin lets you translate web pages between several languages automatically.\"\n",
    "]\n",
    "references = [\n",
    "    [\n",
    "        \"This plugin allows you to automatically translate web pages between several languages.\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "metric.compute(predictions=predictions, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3306e941-58ff-4286-9f03-41e59e009e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 1.683602693167689,\n",
       " 'counts': [1, 0, 0, 0],\n",
       " 'totals': [4, 3, 2, 1],\n",
       " 'precisions': [25.0, 16.666666666666668, 12.5, 12.5],\n",
       " 'bp': 0.10539922456186433,\n",
       " 'sys_len': 4,\n",
       " 'ref_len': 13}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = [\"This This This This\"]\n",
    "references = [\n",
    "    [\n",
    "        \"This plugin allows you to automatically translate web pages between several languages.\"\n",
    "    ]\n",
    "]\n",
    "# It gives bad results as the predictions are worse and there are many repetitions\n",
    "metric.compute(predictions=predictions, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "930555d7-59da-4c6b-9cd5-c5146fe069e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "\n",
    "    decode_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decode_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decode_preds = [pred.strip() for pred in decode_preds]\n",
    "    decode_labels = [[label.strip()] for label in decode_labels]\n",
    "\n",
    "    result = metric.compute(predictions=decode_preds, references=decode_labels)\n",
    "    return {\n",
    "        \"BLEU Score\": result[\"score\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64a45573-d845-4597-a8c8-8c1f500c9c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddb683133cf64a839a15117f90009ade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c434a92-9d67-4c8d-82f5-8d250ae144e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    \"marian-finetuned-kde4-en-to-hi\",\n",
    "    eval_strategy=\"no\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    push_to_hub=True,\n",
    "    predict_with_generate=True,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=3,\n",
    "    fp16=True,\n",
    "    save_total_limit=3\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e1db368-6622-4adb-9637-099e31c543a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='262' max='152' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [152/152 1:00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.1635098457336426,\n",
       " 'eval_model_preparation_time': 0.0041,\n",
       " 'eval_BLEU Score': 56.46803856381509,\n",
       " 'eval_runtime': 1031.8196,\n",
       " 'eval_samples_per_second': 9.423,\n",
       " 'eval_steps_per_second': 0.147}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c9f5fa6-adf1-45cb-a02f-72a6805161bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8205' max='8205' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8205/8205 27:46, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.569300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.366700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.245800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.256000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.254800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.100300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.045800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.054600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.078900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>1.022100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.955100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.955600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.929700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.946200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.944100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prafu\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\transformers\\modeling_utils.py:3685: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8205, training_loss=1.1059731083044113, metrics={'train_runtime': 1666.8399, 'train_samples_per_second': 157.491, 'train_steps_per_second': 4.922, 'total_flos': 1894897412997120.0, 'train_loss': 1.1059731083044113, 'epoch': 3.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66b0058-ec5f-484b-9cc3-ec5d375c098b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4a1d04a-fd55-404a-b391-6d91b79d5116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a25697ad00415fbaae2e495b4be48c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading...:   0%|          | 0.00/306M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/praful-goel/marian-finetuned-kde4-en-to-hi/commit/eeb03fe48a640b3d98bf48fb68c63f56b0ccc238', commit_message='Training Completed', commit_description='', oid='eeb03fe48a640b3d98bf48fb68c63f56b0ccc238', pr_url=None, repo_url=RepoUrl('https://huggingface.co/praful-goel/marian-finetuned-kde4-en-to-hi', endpoint='https://huggingface.co', repo_type='model', repo_id='praful-goel/marian-finetuned-kde4-en-to-hi'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub(tags=\"translation\", commit_message=\"Training Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3ece56-f7be-4750-be06-7772ed2e3634",
   "metadata": {},
   "source": [
    "### Using our translation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c10156b-598a-4ef9-9b35-28ab68206123",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b291ecfa-b9d7-4474-b99d-ccebd6630c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'अनुप्रयोग से बाहर होने के लिए एस्केप दबाएँ.'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation_pipeline = pipeline(\"translation\", \"praful-goel/marian-finetuned-kde4-en-to-hi\")\n",
    "\n",
    "translation_pipeline(\"Press Escape to exit the application.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5088f490-699a-4f71-a918-47a80b8c7812",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
